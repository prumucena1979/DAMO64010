{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb006391",
   "metadata": {},
   "source": [
    "\n",
    "# Module 6 — SVM Classification and Kernel Comparison (Health Dataset)\n",
    "**Student:** _[Your Name]_  \n",
    "**Course:** _[Your Course / Term]_  \n",
    "**Date:** 2025-11-04\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete **SVM classification** workflow on a binary **health dataset** (sklearn's *Breast Cancer Wisconsin*). It compares **four kernels** (linear, RBF, polynomial, sigmoid) under **k-fold cross-validation** with **GridSearchCV**, using **ROC-AUC** as the primary selection metric (tie-breakers: **F1**, then **Accuracy**).\n",
    "\n",
    "We include:\n",
    "- **Stratified** train–test split (fixed random state) and **feature scaling**.\n",
    "- **Model selection** with compact grids to avoid overengineering.\n",
    "- **Two ensemble baselines** (RandomForest, GradientBoosting).\n",
    "- **Confusion matrices** and a **bar chart** comparing Accuracy/F1/ROC-AUC.\n",
    "- A **PCA(2D) kernel decision-surface visualization** to contrast margin geometry.\n",
    "- An automatic **Kernel Selection Note (Recommendation)** (≤ 6 lines).\n",
    "- A one-page PDF report exported to `artifacts/Report.pdf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and configuration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb17052",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading and Preprocessing\n",
    "We use the **Breast Cancer Wisconsin** dataset (binary target). Features are standardized, and a **stratified** split preserves class prevalence. Scaling is required for SVMs because margin geometry depends on feature magnitudes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec57c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "# Basic prevalence insight\n",
    "class_counts = y.value_counts().rename({0:'class 0', 1:'class 1'})\n",
    "prevalence = (class_counts / len(y)).round(3)\n",
    "print('Class counts:\\n', class_counts.to_string())\n",
    "print('\\nPrevalence:\\n', prevalence.to_string())\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# We'll use StandardScaler inside pipelines for model training.\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246e381",
   "metadata": {},
   "source": [
    "\n",
    "## Helpers\n",
    "We define:  \n",
    "1) **evaluate_model**: compute ROC-AUC, F1, Accuracy on the held-out test set.  \n",
    "2) **plot_decision_surface_2d**: fit on PCA2D of the training set and visualize decision regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb73736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Return ROC-AUC, F1, Accuracy for the given fitted model and test set.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    # For ROC-AUC on SVM with probability=False we can use decision_function if available\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        scores = model.decision_function(X_test)\n",
    "        # Convert to probability-like by ranking; roc_auc_score accepts scores\n",
    "        roc = roc_auc_score(y_test, scores)\n",
    "    elif hasattr(model, 'predict_proba'):\n",
    "        roc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        # Fallback: use predictions (may be less sensitive)\n",
    "        roc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return roc, f1, acc\n",
    "\n",
    "\n",
    "def plot_decision_surface_2d(clf, X_pca_train, y_train, X_pca_test, y_test, title=''):\n",
    "    \"\"\"\n",
    "    Fit 'clf' on 2D PCA training data, then draw decision regions\n",
    "    and overlay train/test points. Axes labeled as PCA1/PCA2.\n",
    "    \"\"\"\n",
    "    # Fit\n",
    "    clf.fit(X_pca_train, y_train)\n",
    "\n",
    "    # Meshgrid\n",
    "    x_min, x_max = X_pca_train[:, 0].min() - 1.0, X_pca_train[:, 0].max() + 1.0\n",
    "    y_min, y_max = X_pca_train[:, 1].min() - 1.0, X_pca_train[:, 1].max() + 1.0\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Decision values\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        Z = clf.decision_function(grid)\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, levels=20, alpha=0.2)\n",
    "        # Zero contour as boundary\n",
    "        plt.contour(xx, yy, Z, levels=[0], linewidths=1)\n",
    "    else:\n",
    "        Z = clf.predict(grid).reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, alpha=0.2)\n",
    "\n",
    "    # Scatter points\n",
    "    plt.scatter(X_pca_train[:, 0], X_pca_train[:, 1], s=15, marker='o', label='Train')\n",
    "    plt.scatter(X_pca_test[:, 0],  X_pca_test[:, 1],  s=15, marker='^', label='Test')\n",
    "\n",
    "    plt.xlabel('PCA1')\n",
    "    plt.ylabel('PCA2')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad458b6",
   "metadata": {},
   "source": [
    "\n",
    "## Modeling Setup (SVM Kernels + Compact Grids)\n",
    "**Primary metric:** ROC-AUC. Tie-breakers: F1, then Accuracy.  \n",
    "We clarify that **epsilon (ε)** is an SVR hyperparameter; for **classification (SVC)** we tune `C`, `gamma`, and `degree` (poly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Common CV and scoring\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = {'roc': 'roc_auc', 'f1': 'f1', 'acc': 'accuracy'}\n",
    "\n",
    "# Pipelines per kernel\n",
    "pipe_linear = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='linear', random_state=RANDOM_STATE))])\n",
    "pipe_rbf    = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='rbf',    random_state=RANDOM_STATE))])\n",
    "pipe_poly   = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='poly',   random_state=RANDOM_STATE))])\n",
    "pipe_sig    = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='sigmoid',random_state=RANDOM_STATE))])\n",
    "\n",
    "# Compact grids\n",
    "param_linear = {'svc__C': [0.1, 1, 10]}\n",
    "param_rbf    = {'svc__C': [0.1, 1, 10],\n",
    "                'svc__gamma': ['scale', 0.1, 0.01]}\n",
    "param_poly   = {'svc__C': [0.1, 1, 10],\n",
    "                'svc__gamma': ['scale', 0.1, 0.01],\n",
    "                'svc__degree': [2, 3]}\n",
    "param_sig    = {'svc__C': [0.1, 1, 10],\n",
    "                'svc__gamma': ['scale', 0.1, 0.01]}\n",
    "\n",
    "grids = [\n",
    "    ('SVM', 'linear', GridSearchCV(pipe_linear, param_linear, cv=cv, scoring=scoring, refit='roc', n_jobs=-1)),\n",
    "    ('SVM', 'rbf',    GridSearchCV(pipe_rbf,    param_rbf,    cv=cv, scoring=scoring, refit='roc', n_jobs=-1)),\n",
    "    ('SVM', 'poly',   GridSearchCV(pipe_poly,   param_poly,   cv=cv, scoring=scoring, refit='roc', n_jobs=-1)),\n",
    "    ('SVM', 'sigmoid',GridSearchCV(pipe_sig,    param_sig,    cv=cv, scoring=scoring, refit='roc', n_jobs=-1)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc459f7",
   "metadata": {},
   "source": [
    "\n",
    "## Model Fitting (SVMs) and Cross-Validated Selection\n",
    "We run `GridSearchCV` for each kernel and retain the best estimator (by ROC-AUC). We then evaluate on the held-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89806964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "best_estimators = {}\n",
    "\n",
    "for model_name, kernel, grid in grids:\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_estimators[kernel] = grid.best_estimator_\n",
    "    roc, f1, acc = evaluate_model(grid.best_estimator_, X_test, y_test)\n",
    "    results.append([model_name, kernel, roc, f1, acc])\n",
    "    print(f\"{kernel.upper()} best params: {grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Two ensemble baselines with small grids\n",
    "rf = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "gb = Pipeline([('scaler', StandardScaler()), ('gb', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "rf_grid = {'rf__n_estimators': [200, 400], 'rf__max_depth': [None, 5, 10]}\n",
    "gb_grid = {'gb__n_estimators': [100, 200], 'gb__learning_rate': [0.05, 0.1]}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, rf_grid, cv=cv, scoring=scoring, refit='roc', n_jobs=-1)\n",
    "gb_cv = GridSearchCV(gb, gb_grid, cv=cv, scoring=scoring, refit='roc', n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "gb_cv.fit(X_train, y_train)\n",
    "\n",
    "rf_roc, rf_f1, rf_acc = evaluate_model(rf_cv.best_estimator_, X_test, y_test)\n",
    "gb_roc, gb_f1, gb_acc = evaluate_model(gb_cv.best_estimator_, X_test, y_test)\n",
    "\n",
    "results.append(['RandomForest', None, rf_roc, rf_f1, rf_acc])\n",
    "results.append(['GradientBoosting', None, gb_roc, gb_f1, gb_acc])\n",
    "\n",
    "print(\"\\nRF best params:\", rf_cv.best_params_)\n",
    "print(\"GB best params:\", gb_cv.best_params_)\n",
    "\n",
    "metrics_df = pd.DataFrame(results, columns=['model','kernel','ROC_AUC','F1','Accuracy'])\n",
    "metrics_df = metrics_df.sort_values(by=['ROC_AUC','F1','Accuracy'], ascending=False).reset_index(drop=True)\n",
    "metrics_df_rounded = metrics_df.copy()\n",
    "for c in ['ROC_AUC','F1','Accuracy']:\n",
    "    metrics_df_rounded[c] = metrics_df_rounded[c].round(3)\n",
    "metrics_df_rounded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afa85c",
   "metadata": {},
   "source": [
    "\n",
    "## Confusion Matrices (Best SVM vs Ensembles)\n",
    "We visualize confusion matrices for the top SVM and the two ensemble baselines on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91aa3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify top SVM by metric hierarchy (ROC->F1->ACC) among SVM rows\n",
    "svm_only = metrics_df[metrics_df['model'] == 'SVM'].sort_values(by=['ROC_AUC','F1','Accuracy'], ascending=False)\n",
    "top_kernel = svm_only.iloc[0]['kernel']\n",
    "top_svm = best_estimators[top_kernel]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 3.5))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ConfusionMatrixDisplay.from_estimator(top_svm, X_test, y_test, normalize='true', ax=ax1)\n",
    "ax1.set_title(f\"Top SVM ({top_kernel})\")\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ConfusionMatrixDisplay.from_estimator(rf_cv.best_estimator_, X_test, y_test, normalize='true', ax=ax2)\n",
    "ax2.set_title(\"RandomForest\")\n",
    "\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ConfusionMatrixDisplay.from_estimator(gb_cv.best_estimator_, X_test, y_test, normalize='true', ax=ax3)\n",
    "ax3.set_title(\"GradientBoosting\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171820a6",
   "metadata": {},
   "source": [
    "\n",
    "## Metric Comparison (Bar Chart)\n",
    "A compact bar chart contrasting **Accuracy**, **F1**, and **ROC-AUC** across all tuned models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "x = np.arange(len(metrics_df_rounded))\n",
    "width = 0.22\n",
    "\n",
    "plt.bar(x - width, metrics_df_rounded['Accuracy'], width, label='Accuracy')\n",
    "plt.bar(x,          metrics_df_rounded['F1'],       width, label='F1')\n",
    "plt.bar(x + width,  metrics_df_rounded['ROC_AUC'],  width, label='ROC-AUC')\n",
    "\n",
    "plt.xticks(x, [f\"{m}/{k if k is not None else ''}\".strip('/') for m,k in zip(metrics_df_rounded['model'], metrics_df_rounded['kernel'])], rotation=45, ha='right')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Metrics (Test Set)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82eb9ad",
   "metadata": {},
   "source": [
    "\n",
    "## Kernel Difference — Visualization (PCA to 2D)\n",
    "We project **scaled** features to **2D via PCA** (fit on training only) and train each SVM **on the 2D projection** (for visualization only). Plots below show **decision regions** and margin geometry.  \n",
    "**Note:** This 2D view is for interpretability and does **not** represent the full feature space used for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale outside of pipeline for visualization-only PCA fit\n",
    "scaler_vis = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler_vis.transform(X_train)\n",
    "X_test_scaled  = scaler_vis.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca_train = pca.fit_transform(X_train_scaled)\n",
    "X_pca_test  = pca.transform(X_test_scaled)\n",
    "\n",
    "# Build per-kernel SVM using best params but trained on PCA(2D)\n",
    "svm_2d_specs = []\n",
    "for kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n",
    "    best = best_estimators[kernel]\n",
    "    # Extract key params from the tuned best estimator\n",
    "    svc = best.named_steps['svc']\n",
    "    params = dict(kernel=svc.kernel, C=svc.C, gamma=getattr(svc, 'gamma', 'scale'), degree=getattr(svc, 'degree', 3), random_state=RANDOM_STATE)\n",
    "    # Create a fresh SVC with these params (no scaling here, data already PCA-projected)\n",
    "    clf_2d = SVC(kernel=params['kernel'], C=params['C'], gamma=params['gamma'],\n",
    "                 degree=params.get('degree', 3), random_state=RANDOM_STATE)\n",
    "    svm_2d_specs.append((kernel, clf_2d, params))\n",
    "\n",
    "# Plot 2x2 grid\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "for i, (kernel, clf, params) in enumerate(svm_2d_specs, start=1):\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    plt.sca(ax)\n",
    "    title = f\"{kernel.capitalize()} — C={params['C']}, gamma={params.get('gamma','-')}, deg={params.get('degree','-')}\"\n",
    "    plot_decision_surface_2d(clf, X_pca_train, y_train, X_pca_test, y_test, title=title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\"**Caption:** Linear shows planar separability; RBF offers flexible local decision boundaries; Polynomial encodes global curvature (degree-dependent); Sigmoid resembles a squashed linear separator and can underperform without careful scaling/hyperparameters.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a8c7f",
   "metadata": {},
   "source": [
    "\n",
    "## Kernel Selection Note (Recommendation)\n",
    "The short recommendation below is auto-generated from the **tuned** models and **test** metrics, prioritizing **ROC-AUC**, then **F1**, then **Accuracy**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auto-generate recommendation Markdown\n",
    "svm_only_rounded = metrics_df_rounded[metrics_df_rounded['model']=='SVM'].copy()\n",
    "svm_sorted = svm_only_rounded.sort_values(by=['ROC_AUC','F1','Accuracy'], ascending=False).reset_index(drop=True)\n",
    "best_row = svm_sorted.iloc[0]\n",
    "\n",
    "rec_lines = [\n",
    "    f\"**Recommended kernel:** **{best_row['kernel'].upper()}**.\",\n",
    "    f\"It achieved the top ROC-AUC ({best_row['ROC_AUC']}) with strong F1 ({best_row['F1']}) and Accuracy ({best_row['Accuracy']}) on the held-out test set.\",\n",
    "    \"This choice balances bias–variance effectively and yields a margin geometry consistent with the dataset’s class structure.\",\n",
    "    \"Compared with alternatives, it shows lower overfitting risk at tuned hyperparameters while retaining adequate interpretability and efficient compute.\",\n",
    "    \"Decision-surface inspection in the PCA(2D) projection corroborates its superior generalization among the evaluated kernels.\"\n",
    "]\n",
    "display(Markdown('### Kernel Selection Note (Recommendation)\\n' + '\\n'.join(rec_lines[:5])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a1fe5",
   "metadata": {},
   "source": [
    "\n",
    "## Export: One-Page PDF Report\n",
    "We generate a concise PDF (`artifacts/Report.pdf`) summarizing preprocessing, CV setup, best parameters, metrics, the visualization insight, and the **recommended kernel**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "# Compose a compact textual summary for the PDF\n",
    "best_params_text = []\n",
    "for k in ['linear','rbf','poly','sigmoid']:\n",
    "    # Derive best params from fitted best_estimator_\n",
    "    be = best_estimators[k]\n",
    "    svc = be.named_steps['svc']\n",
    "    best_params_text.append(f\"{k}: C={svc.C}, gamma={getattr(svc, 'gamma', 'n/a')}, degree={getattr(svc, 'degree', 'n/a')}\")\n",
    "\n",
    "summary_text = f\"\"\"Module 6 — SVM Classification (Health Dataset)\n",
    "\n",
    "Dataset & Preprocessing:\n",
    "- Breast Cancer Wisconsin (binary). Standardized features. Stratified 70/30 split (random_state={RANDOM_STATE}).\n",
    "\n",
    "Cross-Validation & Grids:\n",
    "- 5-fold StratifiedKFold with GridSearchCV; primary metric ROC-AUC (refit='roc').\n",
    "- Compact grids over C, gamma, degree (poly). (Note: epsilon pertains to SVR, not SVC.)\n",
    "\n",
    "Best SVM Hyperparameters:\n",
    "- {chr(10).join(best_params_text)}\n",
    "\n",
    "Test Metrics (Top Rows):\n",
    "{metrics_df_rounded.head(6).to_string(index=False)}\n",
    "\n",
    "Visualization Insight:\n",
    "- PCA(2D) decision-surface plots show linear vs. non-linear margin geometry; RBF flexibly captures local structure, polynomial adds global curvature, sigmoid resembles squashed linear.\n",
    "\n",
    "Recommendation:\n",
    "- See “Kernel Selection Note (Recommendation)” cell in the notebook (ROC-AUC primary, F1/Accuracy tie-breakers).\n",
    "\"\"\"\n",
    "\n",
    "# Render to a single-page PDF using matplotlib\n",
    "fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait in inches\n",
    "plt.axis('off')\n",
    "wrapped = textwrap.fill(summary_text, width=95)\n",
    "plt.text(0.05, 0.98, wrapped, va='top', ha='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/Report.pdf')\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved Report to artifacts/Report.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38683a0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "- **Metric hierarchy**: ROC-AUC (primary) → F1 → Accuracy.  \n",
    "- **PCA plots**: 2D projection for interpretability — not the full feature space used in evaluation.  \n",
    "- **Grids kept small** to ensure fast runtime and avoid overengineering.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
